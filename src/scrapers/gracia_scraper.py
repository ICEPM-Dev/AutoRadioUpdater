import re
from typing import List, Dict
from .base_scraper import BaseScraper


class GraciaScraper(BaseScraper):
    """Scraper for Gracia a Vosotros radio program"""
    
    def get_episodes(self) -> List[Dict]:
        """Get episodes from Gracia.org website"""
        soup = self.get_page_content(self.base_url)
        if not soup:
            return []
        
        episodes = []
        
        # Look for download links with data-bind attribute (Gracia uses knockout.js)
        # <a class="waves-effect" download="" data-bind="attr: {href: radioBroadcastDownloadMp3UrlPodcast()+'?x-source=website&x-type=download' }">
        download_links = soup.find_all('a', class_='waves-effect', download=True, attrs={'data-bind': True})
        
        # If no data-bind links, look for any waves-effect download links
        if not download_links:
            download_links = soup.find_all('a', class_='waves-effect', download=True)
        
        # If still no links, look for any download links
        if not download_links:
            download_links = soup.find_all('a', download=True)
        
        # Process download links - need to extract URL from data-bind
        for link in download_links:
            # First check if href has the URL directly
            href = link.get('href')
            if href and '.mp3' in href.lower():
                title = "Programa del Día"
                episodes.append({
                    "titulo": title,
                    "audio_url": href,
                    "nombre_programa": self.program_name
                })
                break
            
            # If no href, try to extract from data-bind
            data_bind = link.get('data-bind')
            if data_bind and 'radioBroadcastDownloadMp3UrlPodcast' in data_bind:
                # Extract URL from data-bind attribute
                # Pattern: attr: {href: radioBroadcastDownloadMp3UrlPodcast()+'?x-source=website&x-type=download' }
                url_match = re.search(r'href:\s*radioBroadcastDownloadMp3UrlPodcast\(\)\+[\'"]([^\'\"]+)[\'"]', data_bind)
                if url_match:
                    # The base URL would be generated by JavaScript, but we can try to construct it
                    # Based on the pattern you provided: https://cdn.gty.org/gracia/podcast/20251114.mp3
                    from datetime import datetime
                    today = datetime.now().strftime('%Y%m%d')
                    constructed_url = f"https://cdn.gty.org/gracia/podcast/{today}.mp3"
                    
                    title = "Programa del Día"
                    episodes.append({
                        "titulo": title,
                        "audio_url": constructed_url,
                        "nombre_programa": self.program_name
                    })
                    break
        
        # If still no episodes, construct today's URL directly
        if not episodes:
            from datetime import datetime
            today = datetime.now().strftime('%Y%m%d')
            constructed_url = f"https://cdn.gty.org/gracia/podcast/{today}.mp3"
            
            # Verify the URL exists by checking headers
            try:
                import requests
                response = requests.head(constructed_url, timeout=10)
                if response.status_code == 200:
                    episodes.append({
                        "titulo": f"Programa del Día ({datetime.now().strftime('%d/%m/%Y')})",
                        "audio_url": constructed_url,
                        "nombre_programa": self.program_name
                    })
            except:
                # If today's URL doesn't work, try yesterday
                from datetime import timedelta
                yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
                yesterday_url = f"https://cdn.gty.org/gracia/podcast/{yesterday}.mp3"
                
                try:
                    response = requests.head(yesterday_url, timeout=10)
                    if response.status_code == 200:
                        episodes.append({
                            "titulo": f"Programa de Ayer ({(datetime.now() - timedelta(days=1)).strftime('%d/%m/%Y')})",
                            "audio_url": yesterday_url,
                            "nombre_programa": self.program_name
                        })
                except:
                    pass
        
        # Additional fallback: Look in dropdown buttons
        if not episodes:
            dropdown_buttons = soup.find_all('button', class_='dropdown-button')
            for button in dropdown_buttons:
                # Find parent or sibling elements that might contain the download link
                parent = button.find_parent()
                if parent:
                    mp3_link = parent.find('a', href=re.compile(r'\.mp3', re.I))
                    if mp3_link:
                        href = mp3_link.get('href')
                        if href:
                            episodes.append({
                                "titulo": "Programa del Día",
                                "audio_url": href,
                                "nombre_programa": self.program_name
                            })
                            break
        
        return episodes
    
    def get_audio_url(self, episode_data: Dict) -> str:
        """Extract audio URL - for this scraper, it's already in the episode data"""
        return episode_data.get("audio_url")